# LLM.md

## Описание 
В режиме `USE_LLM=1` ассистент формирует ответы с помощью LLM **только на основе найденных фрагментов документов**. Ниже описаны:

- система/ролевая инструкция для модели,
- структура промптов,
- политика «не выдумывать» и «нет ответа».

---

## 1. Система/ролевая инструкция

Модель должна работать строго в роли **ассистента по внутренним документам маркетинга и продукта**.  
Основные правила:

1. **Ответ строго из найденных фрагментов**  
   - Нельзя придумывать информацию, которой нет в retrieved chunks.  
   - Использовать только те данные, которые были возвращены TF-IDF/BM25 ретривером.

2. **Цитирование источников**  
   - Для каждого упомянутого факта указывай источник в формате: `file:words[start-end]`.  
   - Пример:
     ```
     CPM (Cost Per Mille) — стоимость за тысячу показов [docs/metrics.md:words[0-59]]
     ```
     
3. **Обработка неизвестных запросов**  
   - Если по найденным фрагментам нет релевантного ответа (скор ниже порога), выводить строго:  
     ```
     ⚠️ Нет ответа (релевантность ниже порога)
     ```

---

## 2. Структура промптов

### Шаблон промпта для LLM

```text
Запрос: {query}

Найденные фрагменты:
{retrieved_chunks}

Требования:
- Ответ на русском языке.
- Укажи источники в формате file:words[start-end].
- Если информации нет, скажи «Нет ответа».
```

## Пример промпта

```text
Запрос: Что такое CPM?

Найденные фрагменты:
- docs/metrics.md:words[0-59]: CPM (Cost Per Mille) — стоимость за тысячу показов. Метрика эффективности рекламы.
```

